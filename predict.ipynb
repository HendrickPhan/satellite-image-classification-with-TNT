{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/hieuphandinhminh/Desktop/Repo/Python/test-timm/pytorch-image-models\n",
      "/Users/hieuphandinhminh/Desktop/Repo/Python/test-timm/pytorch-image-models\n"
     ]
    }
   ],
   "source": [
    "%cd pytorch-image-models\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hieuphandinhminh/Desktop/Repo/Python/test-timm/venv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import timm\n",
    "checkpoint_path = './output/train/20230312-154938-tnt_s_patch16_224-224/model_best.pth.tar'\n",
    "model = timm.create_model('tnt_s_patch16_224',pretrained=False, checkpoint_path=checkpoint_path,num_classes=4).eval()\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load sample image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=64x64>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "image_path = '../Satellite/train/water/SeaLake_2857.jpg'\n",
    "image = Image.open(image_path)\n",
    "image"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load transform from model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = timm.data.create_transform(\n",
    "    **timm.data.resolve_data_config(model.pretrained_cfg)\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can prepare this image for the model by passing it to the transform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 224, 224])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_tensor = transform(image)\n",
    "image_tensor.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can pass that image to the model to get the predictions. We use unsqueeze(0) in this case, as the model is expecting a batch dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model(image_tensor.unsqueeze(0))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the predicted probabilities, we apply softmax to the output. This leaves us with a tensor of shape (num_classes,)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "probabilities = torch.nn.functional.softmax(output[0], dim=0)\n",
    "probabilities.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now weâ€™ll find the top 5 predicted class indexes and values using torch.topk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'water', 'value': 0.8497885465621948},\n",
       " {'label': 'forest', 'value': 0.10480119287967682},\n",
       " {'label': 'desert', 'value': 0.02495712600648403},\n",
       " {'label': 'cloudy', 'value': 0.020453084260225296}]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values, indices = torch.topk(probabilities, 4)\n",
    "labels = [\"cloudy\", \"desert\", \"forest\", \"water\"]\n",
    "[{'label': labels[idx], 'value': val.item()} for val, idx in zip(values, indices)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
